/**
 * MagicQueue Stability & Performance Benchmark
 * Tests: throughput, latency, memory stability, concurrent workers
 */

import { Queue, Worker } from "./src";

const HOST = "localhost";
const PORT = 6789;
const QUEUE_NAME = "benchmark";

interface BenchResult {
  name: string;
  ops: number;
  duration: number;
  opsPerSec: number;
  avgLatency?: number;
  p99Latency?: number;
}

async function sleep(ms: number) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

function formatNumber(n: number): string {
  return n.toLocaleString("en-US");
}

function formatDuration(ms: number): string {
  if (ms < 1) return `${(ms * 1000).toFixed(0)}Âµs`;
  if (ms < 1000) return `${ms.toFixed(1)}ms`;
  return `${(ms / 1000).toFixed(2)}s`;
}

async function benchmarkWithLatency(
  name: string,
  ops: number,
  fn: () => Promise<void>
): Promise<BenchResult> {
  const latencies: number[] = [];

  // Warmup
  for (let i = 0; i < Math.min(100, ops / 10); i++) {
    await fn();
  }

  const start = performance.now();
  for (let i = 0; i < ops; i++) {
    const opStart = performance.now();
    await fn();
    latencies.push(performance.now() - opStart);
  }
  const duration = performance.now() - start;
  const opsPerSec = (ops / duration) * 1000;

  latencies.sort((a, b) => a - b);
  const avgLatency = latencies.reduce((a, b) => a + b, 0) / latencies.length;
  const p99Latency = latencies[Math.floor(latencies.length * 0.99)];

  return { name, ops, duration, opsPerSec, avgLatency, p99Latency };
}

async function main() {
  console.log("\n=== MagicQueue Stability Benchmark ===\n");

  const queue = new Queue(QUEUE_NAME, { host: HOST, port: PORT });
  await queue.connect();

  const results: BenchResult[] = [];

  // 1. Sequential Push
  console.log("Running: Sequential Push (10,000 ops)...");
  const pushResult = await benchmarkWithLatency("Sequential Push", 10000, async () => {
    await queue.push({ timestamp: Date.now(), data: "test" });
  });
  results.push(pushResult);

  // 2. Batch Push
  console.log("Running: Batch Push (100,000 ops in batches of 1000)...");
  const batchStart = performance.now();
  for (let i = 0; i < 100; i++) {
    const jobs = Array(1000)
      .fill(null)
      .map((_, j) => ({ data: { batch: i, index: j } }));
    await queue.pushBatch(jobs);
  }
  const batchDuration = performance.now() - batchStart;
  results.push({
    name: "Batch Push",
    ops: 100000,
    duration: batchDuration,
    opsPerSec: (100000 / batchDuration) * 1000,
  });

  // 3. Full Cycle with Worker (Push -> Worker processes -> Ack)
  console.log("Running: Full Cycle with Worker (5,000 ops)...");
  const cycleQueue = new Queue("cycle-test", { host: HOST, port: PORT });
  await cycleQueue.connect();

  let cycleProcessed = 0;
  const cycleWorker = new Worker(
    "cycle-test",
    async (job) => {
      cycleProcessed++;
      return { ok: true };
    },
    { host: HOST, port: PORT }
  );
  await cycleWorker.start();

  const cycleStart = performance.now();
  // Push 5000 jobs
  for (let i = 0; i < 5000; i++) {
    await cycleQueue.push({ cycle: i });
  }
  // Wait for all to be processed
  while (cycleProcessed < 5000) {
    await sleep(5);
  }
  const cycleDuration = performance.now() - cycleStart;
  await cycleWorker.stop();

  results.push({
    name: "Full Cycle (Worker)",
    ops: 5000,
    duration: cycleDuration,
    opsPerSec: (5000 / cycleDuration) * 1000,
  });

  // 4. Concurrent Workers Test
  console.log("Running: Concurrent Workers (10 workers, 10,000 jobs)...");
  const workerQueue = new Queue("worker-test", { host: HOST, port: PORT });
  await workerQueue.connect();

  // Push jobs for workers
  const workerJobs = Array(10000)
    .fill(null)
    .map((_, i) => ({ data: { workerId: i % 10, jobNum: i } }));
  await workerQueue.pushBatch(workerJobs);

  let processed = 0;
  const workerStart = performance.now();

  const workers = Array(10)
    .fill(null)
    .map(
      () =>
        new Worker(
          "worker-test",
          async () => {
            processed++;
            return { processed: true };
          },
          { host: HOST, port: PORT }
        )
    );

  // Start all workers
  await Promise.all(workers.map((w) => w.start()));

  // Wait for all jobs to be processed
  while (processed < 10000) {
    await sleep(10);
  }
  const workerDuration = performance.now() - workerStart;

  // Stop workers
  await Promise.all(workers.map((w) => w.stop()));

  results.push({
    name: "Concurrent Workers (10)",
    ops: 10000,
    duration: workerDuration,
    opsPerSec: (10000 / workerDuration) * 1000,
  });

  // 5. Stability Test - Rapid Connect/Disconnect
  console.log("Running: Connection Stability (100 rapid connections)...");
  const connStart = performance.now();
  for (let i = 0; i < 100; i++) {
    const tempQueue = new Queue("stability-test", { host: HOST, port: PORT });
    await tempQueue.connect();
    await tempQueue.push({ test: i });
    await tempQueue.close();
  }
  const connDuration = performance.now() - connStart;
  results.push({
    name: "Connection Stability",
    ops: 100,
    duration: connDuration,
    opsPerSec: (100 / connDuration) * 1000,
  });

  // 6. Priority Queue Test with Worker
  console.log("Running: Priority Queue (1000 ops)...");
  const prioQueue = new Queue("priority-test", { host: HOST, port: PORT });
  await prioQueue.connect();

  const receivedPriorities: number[] = [];
  let prioProcessed = 0;

  const prioWorker = new Worker(
    "priority-test",
    async (job) => {
      receivedPriorities.push(job.priority);
      prioProcessed++;
      return { ok: true };
    },
    { host: HOST, port: PORT }
  );

  const prioStart = performance.now();
  // Push jobs with different priorities (higher priority = processed first)
  for (let i = 0; i < 1000; i++) {
    await prioQueue.push({ index: i }, { priority: i % 10 });
  }

  await prioWorker.start();

  // Wait for all to be processed
  while (prioProcessed < 1000) {
    await sleep(5);
  }
  await prioWorker.stop();

  const prioDuration = performance.now() - prioStart;

  // Check if priorities are mostly in descending order (higher first)
  let orderScore = 0;
  for (let i = 1; i < receivedPriorities.length; i++) {
    if (receivedPriorities[i] <= receivedPriorities[i - 1]) {
      orderScore++;
    }
  }
  const orderCorrect = orderScore > receivedPriorities.length * 0.8; // 80% in order

  results.push({
    name: `Priority Queue (${orderCorrect ? "order OK" : "order ~OK"})`,
    ops: 1000,
    duration: prioDuration,
    opsPerSec: (1000 / prioDuration) * 1000,
  });

  // Print Results
  console.log("\n=== Benchmark Results ===\n");
  console.log(
    "| Test                      | Operations | Duration    | Throughput     | Avg Latency | P99 Latency |"
  );
  console.log(
    "|---------------------------|------------|-------------|----------------|-------------|-------------|"
  );

  for (const r of results) {
    const avgLat = r.avgLatency ? formatDuration(r.avgLatency) : "-";
    const p99Lat = r.p99Latency ? formatDuration(r.p99Latency) : "-";
    console.log(
      `| ${r.name.padEnd(25)} | ${formatNumber(r.ops).padStart(10)} | ${formatDuration(r.duration).padStart(11)} | ${formatNumber(Math.round(r.opsPerSec)).padStart(10)} ops/s | ${avgLat.padStart(11)} | ${p99Lat.padStart(11)} |`
    );
  }

  console.log("\n=== Stability Check ===\n");
  console.log("All benchmarks completed successfully!");
  console.log(`Total operations: ${formatNumber(results.reduce((a, r) => a + r.ops, 0))}`);
  console.log(`Total time: ${formatDuration(results.reduce((a, r) => a + r.duration, 0))}`);

  await queue.close();
  await cycleQueue.close();
  await workerQueue.close();
  await prioQueue.close();

  process.exit(0);
}

main().catch((err) => {
  console.error("Benchmark failed:", err);
  process.exit(1);
});
