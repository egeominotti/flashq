/**
 * 1 Million Jobs Benchmark with Engineering Metrics
 * Tracks: Memory (Client + Server), Latency (P50/P95/P99/P99.9), Throughput variance
 * Generates HTML report with interactive charts
 */
import { Queue, Worker } from "../src";

const TOTAL_JOBS = 1_000_000;
const BATCH_SIZE = 1000;
const NUM_WORKERS = 16;
const CONCURRENCY_PER_WORKER = 100;
const NUM_RUNS = 100;
const SERVER_HTTP_PORT = 6790; // flashQ HTTP API port

// Latency tracking with reservoir sampling for memory efficiency
class LatencyTracker {
  private samples: number[] = [];
  private readonly maxSamples = 100_000; // Keep max 100K samples
  private count = 0;
  private sum = 0;
  private min = Infinity;
  private max = -Infinity;

  add(latencyMs: number): void {
    this.count++;
    this.sum += latencyMs;
    if (latencyMs < this.min) this.min = latencyMs;
    if (latencyMs > this.max) this.max = latencyMs;

    // Reservoir sampling for percentile calculation
    if (this.samples.length < this.maxSamples) {
      this.samples.push(latencyMs);
    } else {
      // Random replacement for samples beyond maxSamples
      const idx = Math.floor(Math.random() * this.count);
      if (idx < this.maxSamples) {
        this.samples[idx] = latencyMs;
      }
    }
  }

  getStats(): LatencyStats {
    if (this.samples.length === 0) {
      return {
        count: 0,
        min: 0,
        max: 0,
        avg: 0,
        p50: 0,
        p95: 0,
        p99: 0,
        p999: 0,
      };
    }

    const sorted = [...this.samples].sort((a, b) => a - b);
    const percentile = (p: number) => {
      const idx = Math.ceil((p / 100) * sorted.length) - 1;
      return sorted[Math.max(0, idx)];
    };

    return {
      count: this.count,
      min: this.min,
      max: this.max,
      avg: this.sum / this.count,
      p50: percentile(50),
      p95: percentile(95),
      p99: percentile(99),
      p999: percentile(99.9),
    };
  }

  reset(): void {
    this.samples = [];
    this.count = 0;
    this.sum = 0;
    this.min = Infinity;
    this.max = -Infinity;
  }
}

interface LatencyStats {
  count: number;
  min: number;
  max: number;
  avg: number;
  p50: number;
  p95: number;
  p99: number;
  p999: number;
}

interface MemorySnapshot {
  timestamp: number;
  rss: number; // Resident Set Size (total memory)
  heapUsed: number; // V8 heap used
  heapTotal: number; // V8 heap total
  external: number; // C++ objects bound to JS
}

interface MemoryStats {
  peakRss: number;
  peakHeapUsed: number;
  avgRss: number;
  avgHeapUsed: number;
  startRss: number;
  endRss: number;
  deltaRss: number;
}

// Server (Rust) memory tracking
interface ServerMemorySnapshot {
  timestamp: number;
  memoryUsedMb: number;
  cpuPercent: number;
  tcpConnections: number;
}

interface ServerMemoryStats {
  peakMemory: number;
  avgMemory: number;
  startMemory: number;
  endMemory: number;
  deltaMemory: number;
}

async function getServerMemory(): Promise<ServerMemorySnapshot | null> {
  try {
    const response = await fetch(
      `http://localhost:${SERVER_HTTP_PORT}/system/metrics`,
    );
    if (!response.ok) return null;
    const data = (await response.json()) as {
      ok: boolean;
      data?: {
        memory_used_mb: number;
        cpu_percent: number;
        tcp_connections: number;
      };
    };
    if (!data.ok || !data.data) return null;
    return {
      timestamp: Date.now(),
      memoryUsedMb: data.data.memory_used_mb,
      cpuPercent: data.data.cpu_percent,
      tcpConnections: data.data.tcp_connections,
    };
  } catch {
    return null;
  }
}

async function resetServer(): Promise<boolean> {
  try {
    const response = await fetch(
      `http://localhost:${SERVER_HTTP_PORT}/server/reset`,
      { method: "POST" },
    );
    return response.ok;
  } catch {
    return false;
  }
}

function calculateServerMemoryStats(
  snapshots: ServerMemorySnapshot[],
): ServerMemoryStats {
  const validSnapshots = snapshots.filter((s) => s !== null);
  if (validSnapshots.length === 0) {
    return {
      peakMemory: 0,
      avgMemory: 0,
      startMemory: 0,
      endMemory: 0,
      deltaMemory: 0,
    };
  }
  const memories = validSnapshots.map((s) => s.memoryUsedMb);
  return {
    peakMemory: Math.max(...memories),
    avgMemory: memories.reduce((s, v) => s + v, 0) / memories.length,
    startMemory: memories[0],
    endMemory: memories[memories.length - 1],
    deltaMemory: memories[memories.length - 1] - memories[0],
  };
}

interface RunResult {
  run: number;
  // Throughput
  pushTime: number;
  pushRate: number;
  processTime: number;
  processRate: number;
  totalTime: number;
  // Counts
  processed: number;
  errors: number;
  dataErrors: number;
  missing: number;
  success: boolean;
  // Latency
  pushLatency: LatencyStats;
  processLatency: LatencyStats;
  e2eLatency: LatencyStats;
  // Memory (Client - Node.js)
  memory: MemoryStats;
  // Memory (Server - Rust)
  serverMemory: ServerMemoryStats;
  // Throughput samples for variance calculation
  throughputSamples: number[];
}

function getMemoryMB(): MemorySnapshot {
  const mem = process.memoryUsage();
  return {
    timestamp: Date.now(),
    rss: mem.rss / 1024 / 1024,
    heapUsed: mem.heapUsed / 1024 / 1024,
    heapTotal: mem.heapTotal / 1024 / 1024,
    external: mem.external / 1024 / 1024,
  };
}

function calculateMemoryStats(snapshots: MemorySnapshot[]): MemoryStats {
  if (snapshots.length === 0) {
    return {
      peakRss: 0,
      peakHeapUsed: 0,
      avgRss: 0,
      avgHeapUsed: 0,
      startRss: 0,
      endRss: 0,
      deltaRss: 0,
    };
  }

  const peakRss = Math.max(...snapshots.map((s) => s.rss));
  const peakHeapUsed = Math.max(...snapshots.map((s) => s.heapUsed));
  const avgRss = snapshots.reduce((s, m) => s + m.rss, 0) / snapshots.length;
  const avgHeapUsed =
    snapshots.reduce((s, m) => s + m.heapUsed, 0) / snapshots.length;
  const startRss = snapshots[0].rss;
  const endRss = snapshots[snapshots.length - 1].rss;

  return {
    peakRss,
    peakHeapUsed,
    avgRss,
    avgHeapUsed,
    startRss,
    endRss,
    deltaRss: endRss - startRss,
  };
}

function stdDev(values: number[]): number {
  if (values.length === 0) return 0;
  const avg = values.reduce((s, v) => s + v, 0) / values.length;
  const squaredDiffs = values.map((v) => Math.pow(v - avg, 2));
  return Math.sqrt(squaredDiffs.reduce((s, v) => s + v, 0) / values.length);
}

function formatMs(ms: number): string {
  if (ms < 1) return `${(ms * 1000).toFixed(0)}¬µs`;
  if (ms < 1000) return `${ms.toFixed(2)}ms`;
  return `${(ms / 1000).toFixed(2)}s`;
}

async function runBenchmark(runNumber: number): Promise<RunResult> {
  const queue = new Queue("million-benchmark", {
    timeout: 30000,
    defaultJobOptions: {
      removeOnComplete: true,
      timeout: 60000,
    },
  });

  console.log(`\n${"=".repeat(80)}`);
  console.log(
    `üöÄ RUN ${runNumber}/${NUM_RUNS} - ${TOTAL_JOBS.toLocaleString()} Jobs`,
  );
  console.log("=".repeat(80));

  // Trackers
  const pushLatencyTracker = new LatencyTracker();
  const processLatencyTracker = new LatencyTracker();
  const e2eLatencyTracker = new LatencyTracker();
  const memorySnapshots: MemorySnapshot[] = [];
  const serverMemorySnapshots: ServerMemorySnapshot[] = [];
  const throughputSamples: number[] = [];

  // Memory sampling interval (client + server)
  const memoryInterval = setInterval(async () => {
    memorySnapshots.push(getMemoryMB());
    const serverMem = await getServerMemory();
    if (serverMem) serverMemorySnapshots.push(serverMem);
  }, 500);

  // Initial memory snapshot
  memorySnapshots.push(getMemoryMB());
  getServerMemory().then((s) => {
    if (s) serverMemorySnapshots.push(s);
  });

  // Clean up queue before starting
  console.log("üìã Cleaning up queue...");
  await queue.obliterate();

  // Force GC if available
  if (global.gc) {
    global.gc();
    await new Promise((r) => setTimeout(r, 100));
  }

  memorySnapshots.push(getMemoryMB());

  // === CONCURRENT PRODUCER-CONSUMER PATTERN ===
  // Workers start FIRST, then push jobs while workers process
  // This gives realistic production latency measurements

  // Create workers FIRST (before pushing)
  console.log(`üë∑ Creating ${NUM_WORKERS} workers...`);
  const workers: Worker[] = [];
  let processed = 0;
  let errors = 0;
  let dataErrors = 0;
  const overallStart = Date.now();
  let lastReport = overallStart;
  let lastProcessed = 0;

  for (let w = 0; w < NUM_WORKERS; w++) {
    const worker = new Worker(
      "million-benchmark",
      async (job) => {
        const data = job.data as {
          index: number;
          value: string;
          pushTime: number;
        };
        const processingStart = Date.now();
        return {
          index: data.index,
          value: data.value,
          pushTime: data.pushTime,
          processingStart,
          completedAt: Date.now(),
        };
      },
      {
        concurrency: CONCURRENCY_PER_WORKER,
        batchSize: 100,
        autorun: false,
      },
    );

    worker.on("completed", (job, result) => {
      processed++;
      const input = job.data as {
        index: number;
        value: string;
        pushTime: number;
      };
      const output = result as {
        index: number;
        value: string;
        pushTime: number;
        processingStart: number;
        completedAt: number;
      };

      // Data integrity check
      if (input.index !== output.index || input.value !== output.value) {
        dataErrors++;
      }

      // Latency tracking
      const processLatency = output.completedAt - output.processingStart;
      const e2eLatency = output.completedAt - input.pushTime;
      processLatencyTracker.add(processLatency);
      e2eLatencyTracker.add(e2eLatency);
    });

    worker.on("failed", () => {
      errors++;
    });

    workers.push(worker);
  }

  // Start all workers BEFORE pushing (concurrent producer-consumer)
  await Promise.all(workers.map((w) => w.start()));
  console.log(`‚úÖ Workers started, now pushing jobs concurrently...`);

  // Push jobs WHILE workers are processing (producer-consumer pattern)
  console.log(`üì§ Pushing ${TOTAL_JOBS.toLocaleString()} jobs...`);
  const pushStart = Date.now();

  let pushed = 0;
  const pushPromise = (async () => {
    for (let i = 0; i < TOTAL_JOBS; i += BATCH_SIZE) {
      const batchCount = Math.min(BATCH_SIZE, TOTAL_JOBS - i);
      const batchStart = Date.now();

      const jobs = Array.from({ length: batchCount }, (_, j) => {
        const jobIndex = i + j;
        return {
          name: "task",
          data: {
            index: jobIndex,
            value: `job-${jobIndex}`,
            pushTime: Date.now(),
          },
        };
      });

      await queue.addBulk(jobs);
      const batchLatency = Date.now() - batchStart;
      pushLatencyTracker.add(batchLatency / batchCount);
      pushed += batchCount;
    }
  })();

  // Don't await here - let push run concurrently with processing

  // Progress reporter with throughput sampling
  const progressInterval = setInterval(() => {
    const now = Date.now();
    const elapsed = (now - overallStart) / 1000;
    const intervalElapsed = (now - lastReport) / 1000;
    const intervalProcessed = processed - lastProcessed;
    const currentRate = Math.round(intervalProcessed / intervalElapsed);
    const avgRate = Math.round(processed / elapsed);
    const pct = ((processed / TOTAL_JOBS) * 100).toFixed(1);
    const mem = getMemoryMB();

    throughputSamples.push(currentRate);

    console.log(
      `   ${processed.toLocaleString()}/${TOTAL_JOBS.toLocaleString()} (${pct}%) | ` +
        `${currentRate.toLocaleString()}/s | Avg: ${avgRate.toLocaleString()}/s | ` +
        `RSS: ${mem.rss.toFixed(0)}MB | Heap: ${mem.heapUsed.toFixed(0)}MB`,
    );

    lastReport = now;
    lastProcessed = processed;
  }, 5000);

  // Wait for push to complete
  await pushPromise;
  const pushTime = Date.now() - pushStart;
  const pushRate = Math.round(TOTAL_JOBS / (pushTime / 1000));
  console.log(
    `‚úÖ Push complete: ${pushRate.toLocaleString()}/s (${(pushTime / 1000).toFixed(2)}s)`,
  );

  // Wait for all jobs to be processed
  const timeout = Date.now() + 600_000;
  while (processed + errors < TOTAL_JOBS) {
    if (Date.now() > timeout) {
      console.error(
        `‚ùå TIMEOUT: Only ${processed + errors}/${TOTAL_JOBS} jobs completed`,
      );
      break;
    }
    await new Promise((r) => setTimeout(r, 100));
  }

  clearInterval(progressInterval);
  clearInterval(memoryInterval);

  const totalTime = Date.now() - overallStart;
  const processRate = Math.round(TOTAL_JOBS / (totalTime / 1000));

  // Final memory snapshot (client + server)
  memorySnapshots.push(getMemoryMB());
  const finalServerMem = await getServerMemory();
  if (finalServerMem) serverMemorySnapshots.push(finalServerMem);

  // Stop all workers
  await Promise.all(workers.map((w) => w.close()));

  // Cleanup
  await queue.obliterate();
  await queue.close();

  const totalHandled = processed + errors;
  const allAccountedFor = totalHandled === TOTAL_JOBS;
  const success = errors === 0 && dataErrors === 0 && allAccountedFor;

  // Get stats (client + server)
  const pushLatency = pushLatencyTracker.getStats();
  const processLatency = processLatencyTracker.getStats();
  const e2eLatency = e2eLatencyTracker.getStats();
  const memory = calculateMemoryStats(memorySnapshots);
  const serverMemory = calculateServerMemoryStats(serverMemorySnapshots);

  if (!allAccountedFor) {
    console.error(
      `‚ùå MISSING JOBS: ${totalHandled}/${TOTAL_JOBS} (${TOTAL_JOBS - totalHandled} lost)`,
    );
  }

  // Detailed run summary
  console.log(`\n${"‚îÄ".repeat(80)}`);
  console.log(`üìä Run ${runNumber} Summary`);
  console.log(`${"‚îÄ".repeat(80)}`);
  console.log(
    `   Throughput: Push ${pushRate.toLocaleString()}/s | Process ${processRate.toLocaleString()}/s`,
  );
  console.log(
    `   Latency E2E: P50=${formatMs(e2eLatency.p50)} P95=${formatMs(e2eLatency.p95)} P99=${formatMs(e2eLatency.p99)} P99.9=${formatMs(e2eLatency.p999)}`,
  );
  console.log(
    `   Latency Process: P50=${formatMs(processLatency.p50)} P95=${formatMs(processLatency.p95)} P99=${formatMs(processLatency.p99)}`,
  );
  console.log(
    `   Client Memory: Peak=${memory.peakRss.toFixed(0)}MB | Delta=${memory.deltaRss.toFixed(1)}MB`,
  );
  console.log(
    `   Server Memory: Peak=${serverMemory.peakMemory.toFixed(0)}MB | Delta=${serverMemory.deltaMemory.toFixed(1)}MB`,
  );
  console.log(`   Status: ${success ? "‚úÖ PASS" : "‚ùå FAIL"}`);

  // In concurrent mode, processTime = totalTime (push and process overlap)
  const processTime = totalTime;

  return {
    run: runNumber,
    pushTime,
    pushRate,
    processTime,
    processRate,
    totalTime,
    processed,
    errors,
    dataErrors,
    missing: TOTAL_JOBS - totalHandled,
    success,
    pushLatency,
    processLatency,
    e2eLatency,
    memory,
    serverMemory,
    throughputSamples,
  };
}

// Main execution
console.log("=".repeat(80));
console.log("üöÄ flashQ ENGINEERING BENCHMARK");
console.log("=".repeat(80));
console.log(`Jobs per run: ${TOTAL_JOBS.toLocaleString()}`);
console.log(`Total jobs: ${(TOTAL_JOBS * NUM_RUNS).toLocaleString()}`);
console.log(`Workers: ${NUM_WORKERS}`);
console.log(`Concurrency/worker: ${CONCURRENCY_PER_WORKER}`);
console.log(`Total concurrency: ${NUM_WORKERS * CONCURRENCY_PER_WORKER}`);
console.log(`Node.js: ${process.version}`);
console.log(`Platform: ${process.platform} ${process.arch}`);
console.log("=".repeat(80));

// Initial server reset for clean baseline
console.log("\nüßπ Initial server reset for clean baseline...");
const initialReset = await resetServer();
if (initialReset) {
  await new Promise((r) => setTimeout(r, 1000)); // Wait for full cleanup
  const initialMem = await getServerMemory();
  console.log(
    `‚úÖ Server reset complete. Baseline memory: ${initialMem?.memoryUsedMb.toFixed(0) ?? "N/A"}MB`,
  );
} else {
  console.log("‚ö†Ô∏è  Server reset not available");
}

const results: RunResult[] = [];
const overallStart = Date.now();

for (let run = 1; run <= NUM_RUNS; run++) {
  const result = await runBenchmark(run);
  results.push(result);
}

const overallTime = Date.now() - overallStart;

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// FINAL ENGINEERING REPORT
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
console.log("\n" + "‚ïê".repeat(80));
console.log("üìä ENGINEERING REPORT - COMPLETE ANALYSIS");
console.log("‚ïê".repeat(80));

// 1. Throughput Summary Table
console.log(
  "\n‚îå‚îÄ THROUGHPUT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log(
  "‚îÇ Run  ‚îÇ Push Rate    ‚îÇ Process Rate ‚îÇ Total Time ‚îÇ Status                 ‚îÇ",
);
console.log(
  "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
);

for (const r of results) {
  let status = "‚úÖ OK";
  if (!r.success) {
    const issues = [];
    if (r.errors > 0) issues.push(`E:${r.errors}`);
    if (r.dataErrors > 0) issues.push(`D:${r.dataErrors}`);
    if (r.missing > 0) issues.push(`M:${r.missing}`);
    status = `‚ùå ${issues.join(" ")}`;
  }
  console.log(
    `‚îÇ #${r.run.toString().padStart(2)}  ‚îÇ ` +
      `${r.pushRate.toLocaleString().padStart(10)}/s ‚îÇ ` +
      `${r.processRate.toLocaleString().padStart(10)}/s ‚îÇ ` +
      `${(r.totalTime / 1000).toFixed(2).padStart(8)}s ‚îÇ ` +
      `${status.padEnd(22)} ‚îÇ`,
  );
}
console.log(
  "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
);

// 2. Throughput Statistics
const pushRates = results.map((r) => r.pushRate);
const processRates = results.map((r) => r.processRate);
const avgPushRate = Math.round(
  pushRates.reduce((s, v) => s + v, 0) / pushRates.length,
);
const avgProcessRate = Math.round(
  processRates.reduce((s, v) => s + v, 0) / processRates.length,
);

console.log(
  "\n‚îå‚îÄ THROUGHPUT STATISTICS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log(
  `‚îÇ Push Rate:    Avg=${avgPushRate.toLocaleString().padStart(8)}/s  Min=${Math.min(
    ...pushRates,
  )
    .toLocaleString()
    .padStart(8)}/s  Max=${Math.max(...pushRates)
    .toLocaleString()
    .padStart(8)}/s  StdDev=${stdDev(pushRates).toFixed(0).padStart(6)} ‚îÇ`,
);
console.log(
  `‚îÇ Process Rate: Avg=${avgProcessRate.toLocaleString().padStart(8)}/s  Min=${Math.min(
    ...processRates,
  )
    .toLocaleString()
    .padStart(8)}/s  Max=${Math.max(...processRates)
    .toLocaleString()
    .padStart(8)}/s  StdDev=${stdDev(processRates).toFixed(0).padStart(6)} ‚îÇ`,
);
console.log(
  "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
);

// 3. Latency Analysis
console.log(
  "\n‚îå‚îÄ LATENCY ANALYSIS (End-to-End) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log(
  "‚îÇ Run  ‚îÇ    P50    ‚îÇ    P95    ‚îÇ    P99    ‚îÇ   P99.9   ‚îÇ    Max    ‚îÇ  Avg    ‚îÇ",
);
console.log(
  "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
);

for (const r of results) {
  const e = r.e2eLatency;
  console.log(
    `‚îÇ #${r.run.toString().padStart(2)}  ‚îÇ ` +
      `${formatMs(e.p50).padStart(9)} ‚îÇ ` +
      `${formatMs(e.p95).padStart(9)} ‚îÇ ` +
      `${formatMs(e.p99).padStart(9)} ‚îÇ ` +
      `${formatMs(e.p999).padStart(9)} ‚îÇ ` +
      `${formatMs(e.max).padStart(9)} ‚îÇ ` +
      `${formatMs(e.avg).padStart(7)} ‚îÇ`,
  );
}
console.log(
  "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
);

// Aggregate latency stats
const allP99s = results.map((r) => r.e2eLatency.p99);
const allP999s = results.map((r) => r.e2eLatency.p999);
const avgP99 = allP99s.reduce((s, v) => s + v, 0) / allP99s.length;
const avgP999 = allP999s.reduce((s, v) => s + v, 0) / allP999s.length;
const maxP99 = Math.max(...allP99s);
const maxP999 = Math.max(...allP999s);

console.log(
  "\n‚îå‚îÄ LATENCY SUMMARY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log(
  `‚îÇ P99  (E2E): Avg=${formatMs(avgP99).padStart(9)}  Max=${formatMs(maxP99).padStart(9)}  StdDev=${formatMs(stdDev(allP99s)).padStart(9)}              ‚îÇ`,
);
console.log(
  `‚îÇ P99.9(E2E): Avg=${formatMs(avgP999).padStart(9)}  Max=${formatMs(maxP999).padStart(9)}  StdDev=${formatMs(stdDev(allP999s)).padStart(9)}              ‚îÇ`,
);
console.log(
  "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
);

// 4. Memory Analysis (Client - Node.js)
console.log(
  "\n‚îå‚îÄ CLIENT MEMORY (Node.js) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log("‚îÇ Run  ‚îÇ Peak RSS  ‚îÇ Peak Heap ‚îÇ Delta RSS ‚îÇ");
console.log("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§");

for (const r of results) {
  const m = r.memory;
  console.log(
    `‚îÇ #${r.run.toString().padStart(2)}  ‚îÇ ` +
      `${m.peakRss.toFixed(0).padStart(7)}MB ‚îÇ ` +
      `${m.peakHeapUsed.toFixed(0).padStart(7)}MB ‚îÇ ` +
      `${(m.deltaRss >= 0 ? "+" : "") + m.deltaRss.toFixed(1).padStart(6)}MB ‚îÇ`,
  );
}
console.log("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò");

// 4b. Server Memory Analysis (Rust)
console.log(
  "\n‚îå‚îÄ SERVER MEMORY (Rust) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log("‚îÇ Run  ‚îÇ Peak Mem  ‚îÇ Avg Mem   ‚îÇ Delta Mem ‚îÇ");
console.log("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§");

for (const r of results) {
  const s = r.serverMemory;
  console.log(
    `‚îÇ #${r.run.toString().padStart(2)}  ‚îÇ ` +
      `${s.peakMemory.toFixed(0).padStart(7)}MB ‚îÇ ` +
      `${s.avgMemory.toFixed(0).padStart(7)}MB ‚îÇ ` +
      `${(s.deltaMemory >= 0 ? "+" : "") + s.deltaMemory.toFixed(1).padStart(6)}MB ‚îÇ`,
  );
}
console.log("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò");

// Memory statistics
const peakRsss = results.map((r) => r.memory.peakRss);
const deltaRsss = results.map((r) => r.memory.deltaRss);
const serverPeaks = results.map((r) => r.serverMemory.peakMemory);
const serverDeltas = results.map((r) => r.serverMemory.deltaMemory);

console.log(
  "\n‚îå‚îÄ MEMORY SUMMARY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log(
  `‚îÇ Client Peak: Avg=${(peakRsss.reduce((s, v) => s + v, 0) / peakRsss.length).toFixed(0).padStart(5)}MB  Max=${Math.max(
    ...peakRsss,
  )
    .toFixed(0)
    .padStart(
      5,
    )}MB  Delta=${(deltaRsss.reduce((s, v) => s + v, 0) / deltaRsss.length).toFixed(1).padStart(6)}MB ‚îÇ`,
);
console.log(
  `‚îÇ Server Peak: Avg=${(serverPeaks.reduce((s, v) => s + v, 0) / serverPeaks.length).toFixed(0).padStart(5)}MB  Max=${Math.max(
    ...serverPeaks,
  )
    .toFixed(0)
    .padStart(
      5,
    )}MB  Delta=${(serverDeltas.reduce((s, v) => s + v, 0) / serverDeltas.length).toFixed(1).padStart(6)}MB ‚îÇ`,
);
console.log(
  "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
);

// 5. Throughput Variance Analysis
const allThroughputSamples = results.flatMap((r) => r.throughputSamples);
const throughputStdDev = stdDev(allThroughputSamples);
const throughputCV = (throughputStdDev / avgProcessRate) * 100; // Coefficient of variation

console.log(
  "\n‚îå‚îÄ THROUGHPUT STABILITY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
);
console.log(
  `‚îÇ Coefficient of Variation: ${throughputCV.toFixed(2)}% (lower = more stable)                        ‚îÇ`,
);
console.log(
  `‚îÇ Standard Deviation: ${throughputStdDev.toFixed(0)} jobs/sec                                        ‚îÇ`,
);
console.log(
  `‚îÇ Sample count: ${allThroughputSamples.length} throughput measurements                                  ‚îÇ`,
);
console.log(
  "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
);

// 6. Overall Summary
const successCount = results.filter((r) => r.success).length;
const totalProcessed = results.reduce((s, r) => s + r.processed, 0);
const totalErrors = results.reduce((s, r) => s + r.errors, 0);
const totalDataErrors = results.reduce((s, r) => s + r.dataErrors, 0);
const totalMissing = results.reduce((s, r) => s + r.missing, 0);

console.log("\n" + "‚ïê".repeat(80));
console.log("üìà FINAL SUMMARY");
console.log("‚ïê".repeat(80));
console.log(`   Total runs: ${NUM_RUNS}`);
console.log(
  `   Passed: ${successCount}/${NUM_RUNS} (${((successCount / NUM_RUNS) * 100).toFixed(1)}%)`,
);
console.log(
  `   Total jobs pushed: ${(TOTAL_JOBS * NUM_RUNS).toLocaleString()}`,
);
console.log(`   Total processed: ${totalProcessed.toLocaleString()}`);
if (totalErrors > 0)
  console.log(`   Total errors: ${totalErrors.toLocaleString()}`);
if (totalDataErrors > 0)
  console.log(
    `   Total data integrity errors: ${totalDataErrors.toLocaleString()}`,
  );
if (totalMissing > 0)
  console.log(`   Total missing jobs: ${totalMissing.toLocaleString()}`);
console.log(`   Total time: ${(overallTime / 1000 / 60).toFixed(2)} minutes`);
console.log(`   Avg throughput: ${avgProcessRate.toLocaleString()} jobs/sec`);
console.log(`   Avg P99 latency: ${formatMs(avgP99)}`);
console.log(`   Client peak memory: ${Math.max(...peakRsss).toFixed(0)}MB`);
console.log(`   Server peak memory: ${Math.max(...serverPeaks).toFixed(0)}MB`);
console.log("‚ïê".repeat(80));

if (successCount === NUM_RUNS) {
  console.log("\n‚úÖ ALL RUNS PASSED - System is stable and production-ready!");
} else {
  console.log(
    `\n‚ùå ${NUM_RUNS - successCount} RUNS FAILED - Investigation required`,
  );
}

process.exit(successCount === NUM_RUNS ? 0 : 1);
