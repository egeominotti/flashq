<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Documentation - flashQ</title>
  <meta name="description" content="Complete documentation for flashQ - the high-performance job queue for AI workloads. BullMQ-compatible API without Redis.">
  <meta name="keywords" content="flashq documentation, job queue api, bullmq alternative, ai workloads, typescript sdk">
  <meta name="robots" content="index, follow">

  <!-- Open Graph -->
  <meta property="og:title" content="flashQ Documentation">
  <meta property="og:description" content="Complete documentation for the high-performance job queue for AI workloads.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://flashq.dev/docs/">
  <meta property="og:image" content="https://flashq.dev/og-image.png">
  <meta property="og:site_name" content="flashQ">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="flashQ Documentation">
  <meta name="twitter:description" content="Complete documentation for the high-performance job queue for AI workloads.">
  <meta name="twitter:image" content="https://flashq.dev/og-image.png">

  <link rel="canonical" href="https://flashq.dev/docs/">

  <!-- Schema.org JSON-LD -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "TechArticle",
    "headline": "flashQ Documentation",
    "description": "Complete documentation for flashQ - the high-performance job queue for AI workloads.",
    "url": "https://flashq.dev/docs/",
    "author": {
      "@type": "Organization",
      "name": "flashQ"
    },
    "publisher": {
      "@type": "Organization",
      "name": "flashQ",
      "url": "https://flashq.dev"
    }
  }
  </script>

  <!-- Breadcrumb Schema -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BreadcrumbList",
    "itemListElement": [
      {
        "@type": "ListItem",
        "position": 1,
        "name": "Home",
        "item": "https://flashq.dev"
      },
      {
        "@type": "ListItem",
        "position": 2,
        "name": "Documentation",
        "item": "https://flashq.dev/docs/"
      }
    ]
  }
  </script>
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>‚ö°</text></svg>">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">

  <!-- Styles -->
  <link rel="stylesheet" href="styles.css">

  <!-- Highlight.js -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/typescript.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/yaml.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/json.min.js"></script>

  <!-- Lucide Icons -->
  <script src="https://unpkg.com/lucide@latest/dist/umd/lucide.min.js"></script>
</head>
<body>
  <div class="docs-layout">
    <!-- Sidebar -->
    <aside class="sidebar" id="sidebar">
      <div class="sidebar-header">
        <a href="../" class="sidebar-logo">
          <span>‚ö°</span> flashQ
        </a>
        <div class="sidebar-version">v0.1.5</div>
      </div>

      <div class="search-box">
        <input type="text" class="search-input" placeholder="Search docs... (‚åòK)" id="search">
      </div>

      <div class="sidebar-section">
        <div class="sidebar-section-title">Getting Started</div>
        <ul class="sidebar-nav">
          <li><a href="#introduction" class="active">Introduction</a></li>
          <li><a href="#installation">Installation</a></li>
          <li><a href="#quickstart">Quick Start</a></li>
          <li><a href="#concepts">Core Concepts</a></li>
        </ul>
      </div>

      <div class="sidebar-section">
        <div class="sidebar-section-title">Guides</div>
        <ul class="sidebar-nav">
          <li><a href="#queue-api">Queue API</a></li>
          <li><a href="#worker-api">Worker API</a></li>
          <li><a href="#job-options">Job Options</a></li>
          <li><a href="#job-dependencies">Job Dependencies</a></li>
          <li><a href="#rate-limiting">Rate Limiting</a></li>
          <li><a href="#retries">Retries & Backoff</a></li>
          <li><a href="#events">Events</a></li>
        </ul>
      </div>

      <div class="sidebar-section">
        <div class="sidebar-section-title">AI Workloads</div>
        <ul class="sidebar-nav">
          <li><a href="#ai-overview">Overview</a></li>
          <li><a href="#llm-pipelines">LLM Pipelines</a></li>
          <li><a href="#rag-workflows">RAG Workflows</a></li>
          <li><a href="#batch-inference">Batch Inference</a></li>
        </ul>
      </div>

      <div class="sidebar-section">
        <div class="sidebar-section-title">Features</div>
        <ul class="sidebar-nav">
          <li><a href="#cron-jobs">Cron Jobs</a></li>
          <li><a href="#dead-letter-queue">Dead Letter Queue</a></li>
          <li><a href="#progress">Progress Tracking</a></li>
        </ul>
      </div>

      <div class="sidebar-section">
        <div class="sidebar-section-title">Deployment</div>
        <ul class="sidebar-nav">
          <li><a href="#self-hosting">Self-Hosting</a></li>
          <li><a href="#docker">Docker</a></li>
          <li><a href="#configuration">Configuration</a></li>
          <li><a href="#clustering">Clustering (HA)</a></li>
        </ul>
      </div>

      <div class="sidebar-section">
        <div class="sidebar-section-title">Migration</div>
        <ul class="sidebar-nav">
          <li><a href="#from-bullmq">From BullMQ</a></li>
        </ul>
      </div>

      <div class="sidebar-section">
        <div class="sidebar-section-title">Reference</div>
        <ul class="sidebar-nav">
          <li><a href="#api-reference">API Reference</a></li>
          <li><a href="#troubleshooting">Troubleshooting</a></li>
        </ul>
      </div>
    </aside>

    <!-- Main Content -->
    <main class="main-content">

      <!-- Introduction -->
      <section id="introduction">
        <h1>flashQ Documentation</h1>
        <p class="lead">
          flashQ is a high-performance job queue built with Rust. It provides a BullMQ-compatible API
          without requiring Redis, making it perfect for AI workloads, LLM pipelines, and high-throughput applications.
        </p>

        <div class="card-grid">
          <a href="#quickstart" class="card">
            <h4><i data-lucide="rocket" class="icon-inline"></i> Quick Start</h4>
            <p>Get up and running in under 5 minutes with Docker and TypeScript.</p>
          </a>
          <a href="#ai-overview" class="card">
            <h4><i data-lucide="bot" class="icon-inline"></i> AI Workloads</h4>
            <p>Learn how to build LLM pipelines, RAG workflows, and batch inference.</p>
          </a>
          <a href="#from-bullmq" class="card">
            <h4><i data-lucide="package" class="icon-inline"></i> Migration</h4>
            <p>Already using BullMQ? Migrate in minutes with the same API.</p>
          </a>
          <a href="#api-reference" class="card">
            <h4><i data-lucide="book-open" class="icon-inline"></i> API Reference</h4>
            <p>Complete reference for Queue, Worker, and all job options.</p>
          </a>
        </div>

        <h3>Why flashQ?</h3>
        <table>
          <thead>
            <tr>
              <th>Feature</th>
              <th>flashQ</th>
              <th>BullMQ + Redis</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>External dependencies</td>
              <td>None</td>
              <td>Redis server required</td>
            </tr>
            <tr>
              <td>Throughput</td>
              <td><strong>300K jobs/sec</strong></td>
              <td>~30K jobs/sec</td>
            </tr>
            <tr>
              <td>Max payload</td>
              <td><strong>10 MB</strong></td>
              <td>~5 MB recommended</td>
            </tr>
            <tr>
              <td>API compatibility</td>
              <td colspan="2">Same BullMQ-style API</td>
            </tr>
          </tbody>
        </table>
      </section>

      <!-- Installation -->
      <section id="installation">
        <h2>Installation</h2>

        <h3>Server</h3>
        <p>Start the flashQ server using Docker (recommended) or download the binary.</p>

        <h4>Docker (Recommended)</h4>
        <div class="code-block">
          <div class="code-block-header">
            <span>Terminal</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-bash"># Pull multi-arch image (amd64 + arm64)
docker pull ghcr.io/egeominotti/flashq:latest

# Run with dashboard enabled
docker run -d --name flashq \
  -p 6789:6789 \
  -p 6790:6790 \
  -e HTTP=1 \
  ghcr.io/egeominotti/flashq:latest</code></pre>
        </div>

        <h4>Binary</h4>
        <div class="code-block">
          <div class="code-block-header">
            <span>Terminal</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-bash"># Linux x86_64
curl -L https://github.com/egeominotti/flashq/releases/latest/download/flashq-linux-x86_64.tar.gz | tar xz
./flashq-server

# macOS Apple Silicon
curl -L https://github.com/egeominotti/flashq/releases/latest/download/flashq-macos-arm64.tar.gz | tar xz
./flashq-server</code></pre>
        </div>

        <h3>SDK</h3>
        <p>Install the TypeScript SDK in your project:</p>

        <div class="code-block">
          <div class="code-block-header">
            <span>Terminal</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-bash"># Using bun (recommended)
bun add flashq

# Using npm
npm install flashq

# Using yarn
yarn add flashq</code></pre>
        </div>

        <div class="callout callout-info">
          <div class="callout-title">üí° TypeScript Support</div>
          <p>flashQ includes built-in TypeScript definitions. No additional @types package needed.</p>
        </div>
      </section>

      <!-- Quick Start -->
      <section id="quickstart">
        <h2>Quick Start</h2>
        <p>Get your first job queue running in under 5 minutes.</p>

        <div class="steps">
          <div class="step">
            <h4>Start the server</h4>
            <div class="code-block">
              <pre><code class="language-bash">docker run -d -p 6789:6789 ghcr.io/egeominotti/flashq:latest</code></pre>
            </div>
          </div>

          <div class="step">
            <h4>Install the SDK</h4>
            <div class="code-block">
              <pre><code class="language-bash">bun add flashq</code></pre>
            </div>
          </div>

          <div class="step">
            <h4>Create a queue and add jobs</h4>
            <div class="code-block">
              <div class="code-block-header">
                <span>producer.ts</span>
                <button class="copy-btn" onclick="copyCode(this)">Copy</button>
              </div>
              <pre><code class="language-typescript">import { Queue } from 'flashq';

const queue = new Queue('emails');

// Add a job
await queue.add('send-welcome', {
  to: 'user@example.com',
  subject: 'Welcome!'
});

console.log('Job added!');</code></pre>
            </div>
          </div>

          <div class="step">
            <h4>Process jobs with a worker</h4>
            <div class="code-block">
              <div class="code-block-header">
                <span>worker.ts</span>
                <button class="copy-btn" onclick="copyCode(this)">Copy</button>
              </div>
              <pre><code class="language-typescript">import { Worker } from 'flashq';

const worker = new Worker('emails', async (job) => {
  console.log(`Sending email to ${job.data.to}`);

  // Your email sending logic here
  await sendEmail(job.data);

  return { sent: true };
});

worker.on('completed', (job, result) => {
  console.log(`Job ${job.id} completed`);
});

worker.on('failed', (job, error) => {
  console.error(`Job ${job.id} failed: ${error.message}`);
});</code></pre>
            </div>
          </div>
        </div>

        <div class="callout callout-success">
          <div class="callout-title">‚úÖ That's it!</div>
          <p>Your job queue is now running. The worker will automatically process jobs as they're added to the queue.</p>
        </div>
      </section>

      <!-- Core Concepts -->
      <section id="concepts">
        <h2>Core Concepts</h2>

        <h3>Queues</h3>
        <p>A <strong>Queue</strong> is a named container for jobs. Jobs in a queue are processed in priority order (highest first), with FIFO ordering for jobs of the same priority.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const emailQueue = new Queue('emails');
const reportQueue = new Queue('reports');</code></pre>
        </div>

        <h3>Jobs</h3>
        <p>A <strong>Job</strong> is a unit of work with a name, data payload, and optional configuration. Jobs progress through states: <code>waiting</code> ‚Üí <code>active</code> ‚Üí <code>completed</code> or <code>failed</code>.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const job = await queue.add('process-image', {
  imageUrl: 'https://example.com/image.jpg',
  filters: ['resize', 'compress']
}, {
  priority: 10,
  attempts: 3
});</code></pre>
        </div>

        <h3>Workers</h3>
        <p>A <strong>Worker</strong> processes jobs from a queue. Workers can run concurrently and automatically handle job acknowledgment, retries, and error handling.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const worker = new Worker('emails', processor, {
  concurrency: 10  // Process 10 jobs in parallel
});</code></pre>
        </div>

        <h3>Job States</h3>
        <table>
          <thead>
            <tr>
              <th>State</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>waiting</code></td>
              <td>Job is queued and ready to be processed</td>
            </tr>
            <tr>
              <td><code>delayed</code></td>
              <td>Job is scheduled to run at a future time</td>
            </tr>
            <tr>
              <td><code>active</code></td>
              <td>Job is currently being processed by a worker</td>
            </tr>
            <tr>
              <td><code>completed</code></td>
              <td>Job finished successfully</td>
            </tr>
            <tr>
              <td><code>failed</code></td>
              <td>Job failed and exhausted all retry attempts (in DLQ)</td>
            </tr>
            <tr>
              <td><code>waiting-children</code></td>
              <td>Job is waiting for dependent jobs to complete</td>
            </tr>
          </tbody>
        </table>
      </section>

      <!-- Queue API -->
      <section id="queue-api">
        <h2>Queue API</h2>
        <p>The Queue class provides methods for adding jobs and managing queue state.</p>

        <h3>Constructor</h3>
        <div class="code-block">
          <pre><code class="language-typescript">const queue = new Queue(name, options?);</code></pre>
        </div>

        <table>
          <thead>
            <tr>
              <th>Option</th>
              <th>Type</th>
              <th>Default</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>host</code></td>
              <td>string</td>
              <td><code>'localhost'</code></td>
              <td>Server hostname</td>
            </tr>
            <tr>
              <td><code>port</code></td>
              <td>number</td>
              <td><code>6789</code></td>
              <td>Server port</td>
            </tr>
            <tr>
              <td><code>token</code></td>
              <td>string</td>
              <td>-</td>
              <td>Authentication token</td>
            </tr>
          </tbody>
        </table>

        <h3>Methods</h3>

        <h4><code>add(name, data, opts?)</code></h4>
        <p>Add a single job to the queue.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const job = await queue.add('send-email', {
  to: 'user@example.com'
}, {
  priority: 10,
  delay: 5000,
  attempts: 3
});

console.log(job.id); // Unique job ID</code></pre>
        </div>

        <h4><code>addBulk(jobs)</code></h4>
        <p>Add multiple jobs in a single batch operation. More efficient than calling <code>add()</code> multiple times.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const jobs = await queue.addBulk([
  { name: 'send', data: { to: 'a@test.com' } },
  { name: 'send', data: { to: 'b@test.com' }, opts: { priority: 10 } },
  { name: 'send', data: { to: 'c@test.com' }, opts: { delay: 5000 } },
]);</code></pre>
        </div>

        <h4><code>getJob(jobId)</code></h4>
        <p>Get a job by its ID, including current state and data.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const job = await queue.getJob(123);
console.log(job.state);  // 'completed'
console.log(job.result); // { sent: true }</code></pre>
        </div>

        <h4><code>finished(jobId, timeout?)</code> <span class="badge badge-new">New</h4>
        <p>Wait for a job to complete and return its result. Perfect for synchronous workflows.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const job = await queue.add('generate', { prompt });
const result = await queue.finished(job.id, 30000); // 30s timeout
console.log(result); // Worker's return value</code></pre>
        </div>

        <h4><code>getJobCounts()</code></h4>
        <p>Get counts of jobs in each state.</p>
        <div class="code-block">
          <pre><code class="language-typescript">const counts = await queue.getJobCounts();
// { waiting: 10, active: 5, completed: 100, failed: 2, delayed: 3 }</code></pre>
        </div>

        <h4><code>pause()</code> / <code>resume()</code></h4>
        <p>Pause or resume job processing on the queue.</p>
        <div class="code-block">
          <pre><code class="language-typescript">await queue.pause();   // Workers stop pulling jobs
await queue.resume();  // Workers resume pulling jobs</code></pre>
        </div>

        <h4><code>drain()</code></h4>
        <p>Remove all waiting jobs from the queue.</p>
        <div class="code-block">
          <pre><code class="language-typescript">await queue.drain(); // Clear waiting jobs only</code></pre>
        </div>

        <h4><code>obliterate()</code></h4>
        <p>Remove all data associated with the queue (jobs, DLQ, settings).</p>
        <div class="code-block">
          <pre><code class="language-typescript">await queue.obliterate(); // Nuclear option - removes everything</code></pre>
        </div>
        <div class="callout callout-danger">
          <div class="callout-title">‚ö†Ô∏è Warning</div>
          <p><code>obliterate()</code> is irreversible. All jobs and queue data will be permanently deleted.</p>
        </div>
      </section>

      <!-- Job Options -->
      <section id="job-options">
        <h2>Job Options</h2>
        <p>Configure job behavior with these options when calling <code>queue.add()</code>.</p>

        <table>
          <thead>
            <tr>
              <th>Option</th>
              <th>Type</th>
              <th>Default</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>priority</code></td>
              <td>number</td>
              <td><code>0</code></td>
              <td>Higher priority jobs are processed first</td>
            </tr>
            <tr>
              <td><code>delay</code></td>
              <td>number</td>
              <td><code>0</code></td>
              <td>Delay in milliseconds before job becomes available</td>
            </tr>
            <tr>
              <td><code>attempts</code></td>
              <td>number</td>
              <td><code>1</code></td>
              <td>Number of retry attempts on failure</td>
            </tr>
            <tr>
              <td><code>backoff</code></td>
              <td>number | object</td>
              <td>-</td>
              <td>Backoff strategy for retries</td>
            </tr>
            <tr>
              <td><code>timeout</code></td>
              <td>number</td>
              <td>-</td>
              <td>Job processing timeout in milliseconds</td>
            </tr>
            <tr>
              <td><code>jobId</code></td>
              <td>string</td>
              <td>-</td>
              <td>Custom job ID for idempotency</td>
            </tr>
            <tr>
              <td><code>depends_on</code></td>
              <td>number[]</td>
              <td>-</td>
              <td>Job IDs that must complete before this job runs</td>
            </tr>
            <tr>
              <td><code>ttl</code></td>
              <td>number</td>
              <td>-</td>
              <td>Time-to-live: auto-fail if not processed in time</td>
            </tr>
          </tbody>
        </table>

        <h3>Priority</h3>
        <p>Jobs with higher priority values are processed first.</p>
        <div class="code-block">
          <pre><code class="language-typescript">await queue.add('low', data, { priority: 1 });
await queue.add('high', data, { priority: 100 }); // Processed first
await queue.add('urgent', data, { priority: 1000 }); // Processed before 'high'</code></pre>
        </div>

        <h3>Delay</h3>
        <p>Schedule a job to run after a specified delay.</p>
        <div class="code-block">
          <pre><code class="language-typescript">// Run after 5 seconds
await queue.add('reminder', data, { delay: 5000 });

// Run after 1 hour
await queue.add('daily-report', data, { delay: 60 * 60 * 1000 });</code></pre>
        </div>

        <h3>Backoff</h3>
        <p>Configure retry delay strategy.</p>
        <div class="code-block">
          <pre><code class="language-typescript">// Fixed delay: retry after 5s each time
await queue.add('job', data, {
  attempts: 3,
  backoff: 5000
});

// Exponential backoff: 1s, 2s, 4s, 8s...
await queue.add('job', data, {
  attempts: 5,
  backoff: {
    type: 'exponential',
    delay: 1000
  }
});</code></pre>
        </div>

        <h3>Custom Job ID (Idempotency)</h3>
        <p>Use <code>jobId</code> to prevent duplicate jobs. If a job with the same ID already exists, the existing job is returned.</p>
        <div class="code-block">
          <pre><code class="language-typescript">// Only one job per order
await queue.add('process-order', orderData, {
  jobId: `order-${orderId}`
});

// Second call with same jobId returns existing job
await queue.add('process-order', orderData, {
  jobId: `order-${orderId}`
}); // No duplicate created</code></pre>
        </div>
      </section>

      <!-- Job Dependencies -->
      <section id="job-dependencies">
        <h2>Job Dependencies</h2>
        <p>Create workflows where jobs wait for other jobs to complete before running.</p>

        <div class="code-block">
          <pre><code class="language-typescript">// Step 1: Fetch data
const fetchJob = await queue.add('fetch', { url });

// Step 2: Process (waits for fetch to complete)
const processJob = await queue.add('process', { data }, {
  depends_on: [fetchJob.id]
});

// Step 3: Save (waits for process to complete)
const saveJob = await queue.add('save', { destination }, {
  depends_on: [processJob.id]
});

// Wait for the final result
const result = await queue.finished(saveJob.id);</code></pre>
        </div>

        <h3>Multiple Dependencies</h3>
        <p>A job can depend on multiple jobs. It will only run when ALL dependencies have completed.</p>
        <div class="code-block">
          <pre><code class="language-typescript">// Fan-out: multiple parallel jobs
const job1 = await queue.add('task1', data1);
const job2 = await queue.add('task2', data2);
const job3 = await queue.add('task3', data3);

// Fan-in: aggregate results (waits for all 3)
const aggregateJob = await queue.add('aggregate', {}, {
  depends_on: [job1.id, job2.id, job3.id]
});</code></pre>
        </div>

        <div class="callout callout-info">
          <div class="callout-title">üí° AI Pipeline Example</div>
          <p>Dependencies are perfect for RAG pipelines: embed ‚Üí search ‚Üí generate. See <a href="#rag-workflows">RAG Workflows</a> for a complete example.</p>
        </div>
      </section>

      <!-- Worker API -->
      <section id="worker-api">
        <h2>Worker API</h2>
        <p>Workers process jobs from a queue. They automatically handle job acknowledgment, retries, and error handling.</p>

        <h3>Constructor</h3>
        <div class="code-block">
          <pre><code class="language-typescript">const worker = new Worker(queueName, processor, options?);</code></pre>
        </div>

        <h4>Options</h4>
        <table>
          <thead>
            <tr>
              <th>Option</th>
              <th>Type</th>
              <th>Default</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>concurrency</code></td>
              <td>number</td>
              <td><code>1</code></td>
              <td>Number of jobs to process in parallel</td>
            </tr>
            <tr>
              <td><code>autorun</code></td>
              <td>boolean</td>
              <td><code>true</code></td>
              <td>Start processing immediately</td>
            </tr>
            <tr>
              <td><code>host</code></td>
              <td>string</td>
              <td><code>'localhost'</code></td>
              <td>Server hostname</td>
            </tr>
            <tr>
              <td><code>port</code></td>
              <td>number</td>
              <td><code>6789</code></td>
              <td>Server port</td>
            </tr>
          </tbody>
        </table>

        <h3>Processor Function</h3>
        <p>The processor function receives a job object and should return a result (or throw an error).</p>
        <div class="code-block">
          <pre><code class="language-typescript">const worker = new Worker('emails', async (job) => {
  // Access job properties
  console.log(job.id);       // Unique job ID
  console.log(job.name);     // Job name
  console.log(job.data);     // Job payload
  console.log(job.attempts); // Current attempt number

  // Do work...
  const result = await processJob(job.data);

  // Return result (stored with the job)
  return result;
});</code></pre>
        </div>

        <h3>Graceful Shutdown</h3>
        <div class="code-block">
          <pre><code class="language-typescript">// Close worker and wait for active jobs to finish
await worker.close();

// Handle process termination
process.on('SIGTERM', async () => {
  await worker.close();
  process.exit(0);
});</code></pre>
        </div>
      </section>

      <!-- Events -->
      <section id="events">
        <h2>Events</h2>
        <p>Workers emit events for job lifecycle changes.</p>

        <table>
          <thead>
            <tr>
              <th>Event</th>
              <th>Arguments</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>completed</code></td>
              <td><code>(job, result)</code></td>
              <td>Job completed successfully</td>
            </tr>
            <tr>
              <td><code>failed</code></td>
              <td><code>(job, error)</code></td>
              <td>Job failed (after all retries)</td>
            </tr>
            <tr>
              <td><code>error</code></td>
              <td><code>(error)</code></td>
              <td>Worker-level error</td>
            </tr>
            <tr>
              <td><code>active</code></td>
              <td><code>(job)</code></td>
              <td>Job started processing</td>
            </tr>
            <tr>
              <td><code>progress</code></td>
              <td><code>(job, progress)</code></td>
              <td>Job progress updated</td>
            </tr>
          </tbody>
        </table>

        <div class="code-block">
          <pre><code class="language-typescript">worker.on('completed', (job, result) => {
  console.log(`‚úÖ Job ${job.id} completed`, result);
});

worker.on('failed', (job, error) => {
  console.error(`‚ùå Job ${job.id} failed: ${error.message}`);
});

worker.on('active', (job) => {
  console.log(`üîÑ Job ${job.id} started`);
});</code></pre>
        </div>
      </section>

      <!-- Rate Limiting -->
      <section id="rate-limiting">
        <h2>Rate Limiting</h2>
        <p>Control job throughput to avoid overwhelming external APIs or services.</p>

        <div class="code-block">
          <pre><code class="language-typescript">import { FlashQ } from 'flashq';

const client = new FlashQ();

// Limit to 100 jobs per second
await client.setRateLimit('openai-calls', 100);

// Limit to 10 jobs per second (for expensive API)
await client.setRateLimit('anthropic-calls', 10);

// Remove rate limit
await client.clearRateLimit('openai-calls');</code></pre>
        </div>

        <h3>Concurrency Limiting</h3>
        <p>Limit how many jobs can be processed simultaneously across all workers.</p>
        <div class="code-block">
          <pre><code class="language-typescript">// Max 5 concurrent jobs processing
await client.setConcurrency('heavy-tasks', 5);

// Remove concurrency limit
await client.clearConcurrency('heavy-tasks');</code></pre>
        </div>

        <div class="callout callout-info">
          <div class="callout-title">üí° AI Cost Control</div>
          <p>Rate limiting is essential for controlling LLM API costs. Set limits based on your API tier and budget.</p>
        </div>
      </section>

      <!-- Retries & Backoff -->
      <section id="retries">
        <h2>Retries &amp; Backoff</h2>
        <p>Configure automatic retries with exponential backoff for failed jobs.</p>

        <h3>Basic Retries</h3>
        <div class="code-block">
          <pre><code class="language-typescript">// Retry up to 3 times on failure
await queue.add('send-email', emailData, {
  attempts: 3
});</code></pre>
        </div>

        <h3>Fixed Delay Backoff</h3>
        <p>Wait a fixed time between retry attempts.</p>
        <div class="code-block">
          <pre><code class="language-typescript">// Retry after 5 seconds each time
await queue.add('api-call', data, {
  attempts: 5,
  backoff: 5000  // 5 seconds
});</code></pre>
        </div>

        <h3>Exponential Backoff</h3>
        <p>Increase delay exponentially: 1s, 2s, 4s, 8s... Perfect for rate-limited APIs.</p>
        <div class="code-block">
          <pre><code class="language-typescript">// Exponential: base * 2^attempt
await queue.add('openai-request', data, {
  attempts: 5,
  backoff: {
    type: 'exponential',
    delay: 1000  // base delay
  }
});
// Delays: 1s, 2s, 4s, 8s, 16s</code></pre>
        </div>

        <h3>Retry Flow</h3>
        <table>
          <thead>
            <tr>
              <th>Attempt</th>
              <th>Exponential (1s base)</th>
              <th>Fixed (5s)</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>1</td><td>1 second</td><td>5 seconds</td></tr>
            <tr><td>2</td><td>2 seconds</td><td>5 seconds</td></tr>
            <tr><td>3</td><td>4 seconds</td><td>5 seconds</td></tr>
            <tr><td>4</td><td>8 seconds</td><td>5 seconds</td></tr>
            <tr><td>5</td><td>16 seconds</td><td>5 seconds</td></tr>
          </tbody>
        </table>

        <div class="callout callout-warning">
          <div class="callout-title">‚ö†Ô∏è Dead Letter Queue</div>
          <p>After exhausting all attempts, failed jobs are moved to the Dead Letter Queue (DLQ). See <a href="#dead-letter-queue">Dead Letter Queue</a> for handling failed jobs.</p>
        </div>
      </section>

      <!-- AI Overview -->
      <section id="ai-overview">
        <h2>AI Workloads</h2>
        <p>flashQ is optimized for AI/ML workloads with features designed for LLM pipelines, RAG systems, and batch inference.</p>

        <div class="card-grid">
          <div class="card">
            <h4><i data-lucide="git-branch" class="icon-inline"></i> Job Dependencies</h4>
            <p>Chain jobs for multi-step AI workflows. Perfect for RAG: embed ‚Üí search ‚Üí generate.</p>
          </div>
          <div class="card">
            <h4><i data-lucide="gauge" class="icon-inline"></i> Rate Limiting</h4>
            <p>Control API costs with per-queue rate limits. Never exceed your OpenAI/Anthropic quota.</p>
          </div>
          <div class="card">
            <h4><i data-lucide="hard-drive" class="icon-inline"></i> Large Payloads</h4>
            <p>10MB payload support for embeddings, images, and large context windows.</p>
          </div>
          <div class="card">
            <h4><i data-lucide="refresh-ccw" class="icon-inline"></i> Smart Retries</h4>
            <p>Automatic retries with exponential backoff. Handle API rate limits gracefully.</p>
          </div>
        </div>
      </section>

      <!-- RAG Workflows -->
      <section id="rag-workflows">
        <h2>RAG Workflows</h2>
        <p>Build Retrieval-Augmented Generation pipelines with job dependencies.</p>

        <div class="code-block">
          <div class="code-block-header">
            <span>rag-pipeline.ts</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-typescript">import { Queue, Worker } from 'flashq';

const rag = new Queue('rag-pipeline');

// Create RAG pipeline
async function askQuestion(question: string) {
  // Step 1: Embed the question
  const embedJob = await rag.add('embed', { text: question });

  // Step 2: Search vector DB (waits for embedding)
  const searchJob = await rag.add('search', { query: question }, {
    depends_on: [embedJob.id]
  });

  // Step 3: Generate answer (waits for search)
  const generateJob = await rag.add('generate', { question }, {
    depends_on: [searchJob.id],
    priority: 10
  });

  // Wait for result
  return rag.finished(generateJob.id);
}

// Workers for each step
new Worker('rag-pipeline', async (job) => {
  switch (job.name) {
    case 'embed':
      return await openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: job.data.text
      });

    case 'search':
      return await vectorDb.search(job.data.query, { limit: 5 });

    case 'generate':
      return await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: job.data.question }]
      });
  }
}, { concurrency: 10 });

// Usage
const answer = await askQuestion('What is flashQ?');
console.log(answer);</code></pre>
        </div>
      </section>

      <!-- LLM Pipelines -->
      <section id="llm-pipelines">
        <h2>LLM Pipelines</h2>
        <p>Build multi-step LLM workflows with job dependencies, progress tracking, and automatic retries.</p>

        <div class="code-block">
          <div class="code-block-header">
            <span>llm-pipeline.ts</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-typescript">import { Queue, Worker } from 'flashq';

const llm = new Queue('llm-pipeline');

// Multi-step summarization pipeline
async function summarizeDocument(doc: string) {
  // Step 1: Chunk the document
  const chunkJob = await llm.add('chunk', { text: doc });

  // Step 2: Summarize each chunk (parallel)
  const summarizeJob = await llm.add('summarize-chunks', {}, {
    depends_on: [chunkJob.id]
  });

  // Step 3: Combine summaries
  const combineJob = await llm.add('combine', {}, {
    depends_on: [summarizeJob.id],
    priority: 10
  });

  return llm.finished(combineJob.id, 60000);
}

// Worker with progress tracking
new Worker('llm-pipeline', async (job) => {
  if (job.name === 'summarize-chunks') {
    const chunks = job.data.chunks;
    const summaries = [];

    for (let i = 0; i < chunks.length; i++) {
      const summary = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: `Summarize: ${chunks[i]}` }]
      });
      summaries.push(summary);

      // Update progress
      await job.updateProgress(((i + 1) / chunks.length) * 100);
    }

    return { summaries };
  }
}, {
  concurrency: 5
});</code></pre>
        </div>

        <h3>Pipeline Patterns</h3>
        <div class="card-grid">
          <div class="card">
            <h4>Sequential Chain</h4>
            <p>A ‚Üí B ‚Üí C. Each step waits for the previous to complete. Perfect for multi-turn conversations.</p>
          </div>
          <div class="card">
            <h4>Fan-Out / Fan-In</h4>
            <p>Split work into parallel chunks, then aggregate. Ideal for document processing.</p>
          </div>
          <div class="card">
            <h4>Conditional Flow</h4>
            <p>Branch based on intermediate results. Use for AI classification and routing.</p>
          </div>
          <div class="card">
            <h4>Retry with Fallback</h4>
            <p>Try GPT-4, fallback to GPT-3.5 on failure. Automatic with retry configuration.</p>
          </div>
        </div>
      </section>

      <!-- Batch Inference -->
      <section id="batch-inference">
        <h2>Batch Inference</h2>
        <p>Process large datasets efficiently with batch operations and progress tracking.</p>

        <div class="code-block">
          <div class="code-block-header">
            <span>batch-inference.ts</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-typescript">import { Queue, Worker } from 'flashq';

const batch = new Queue('batch-inference');

// Submit batch job for embeddings
async function embedDocuments(documents: string[]) {
  // Split into chunks of 100
  const chunkSize = 100;
  const jobs = [];

  for (let i = 0; i < documents.length; i += chunkSize) {
    const chunk = documents.slice(i, i + chunkSize);
    const job = await batch.add('embed', {
      documents: chunk,
      batchIndex: i / chunkSize
    }, {
      priority: 5,
      attempts: 3,
      backoff: { type: 'exponential', delay: 2000 }
    });
    jobs.push(job);
  }

  // Wait for all jobs
  return Promise.all(jobs.map(j => batch.finished(j.id)));
}

// Worker optimized for batch processing
new Worker('batch-inference', async (job) => {
  const { documents } = job.data;

  // Use OpenAI batch embedding API
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: documents
  });

  return {
    embeddings: response.data.map(d => d.embedding),
    model: response.model,
    usage: response.usage
  };
}, {
  concurrency: 10  // Process 10 batches in parallel
});

// Usage: Process 10,000 documents
const results = await embedDocuments(myDocuments);
console.log(`Processed ${results.length} batches`);</code></pre>
        </div>

        <div class="callout callout-info">
          <div class="callout-title">üí° Large Payload Support</div>
          <p>flashQ supports payloads up to 10MB, making it perfect for passing embeddings (1536-3072 dimensions) between pipeline stages.</p>
        </div>
      </section>

      <!-- Cron Jobs -->
      <section id="cron-jobs">
        <h2>Cron Jobs</h2>
        <p>Schedule recurring jobs with standard cron expressions. flashQ supports 6-field cron (including seconds).</p>

        <div class="code-block">
          <div class="code-block-header">
            <span>cron-jobs.ts</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-typescript">import { FlashQ } from 'flashq';

const client = new FlashQ();

// Every minute
await client.addCron('health-check', {
  queue: 'monitoring',
  schedule: '0 * * * * *',  // sec min hour day month weekday
  data: { type: 'health' }
});

// Every hour at minute 0
await client.addCron('hourly-sync', {
  queue: 'sync',
  schedule: '0 0 * * * *',
  data: { source: 'external-api' }
});

// Every day at 2 AM
await client.addCron('daily-report', {
  queue: 'reports',
  schedule: '0 0 2 * * *',
  data: { reportType: 'daily' }
});

// Every Monday at 9 AM
await client.addCron('weekly-digest', {
  queue: 'emails',
  schedule: '0 0 9 * * 1',
  data: { template: 'weekly-digest' }
});

// List all cron jobs
const crons = await client.listCrons();
console.log(crons);

// Delete a cron job
await client.deleteCron('health-check');</code></pre>
        </div>

        <h3>Cron Expression Format</h3>
        <table>
          <thead>
            <tr>
              <th>Field</th>
              <th>Values</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Second</td><td>0-59</td><td>Optional, defaults to 0</td></tr>
            <tr><td>Minute</td><td>0-59</td><td>Required</td></tr>
            <tr><td>Hour</td><td>0-23</td><td>Required</td></tr>
            <tr><td>Day</td><td>1-31</td><td>Required</td></tr>
            <tr><td>Month</td><td>1-12</td><td>Required</td></tr>
            <tr><td>Weekday</td><td>0-6</td><td>0 = Sunday</td></tr>
          </tbody>
        </table>

        <h3>Common Patterns</h3>
        <table>
          <thead>
            <tr>
              <th>Expression</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><code>0 * * * * *</code></td><td>Every minute</td></tr>
            <tr><td><code>0 0 * * * *</code></td><td>Every hour</td></tr>
            <tr><td><code>0 0 0 * * *</code></td><td>Every day at midnight</td></tr>
            <tr><td><code>0 30 9 * * 1-5</code></td><td>Weekdays at 9:30 AM</td></tr>
            <tr><td><code>0 0 */2 * * *</code></td><td>Every 2 hours</td></tr>
          </tbody>
        </table>
      </section>

      <!-- Dead Letter Queue -->
      <section id="dead-letter-queue">
        <h2>Dead Letter Queue</h2>
        <p>Jobs that fail all retry attempts are moved to the Dead Letter Queue (DLQ) for inspection and manual retry.</p>

        <div class="code-block">
          <div class="code-block-header">
            <span>dlq-handling.ts</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-typescript">import { FlashQ } from 'flashq';

const client = new FlashQ();

// Get failed jobs from DLQ
const failedJobs = await client.getDlq('emails', 10);

for (const job of failedJobs) {
  console.log(`Job ${job.id} failed: ${job.error}`);
  console.log(`Data: ${JSON.stringify(job.data)}`);
  console.log(`Attempts: ${job.attempts}`);
}

// Retry a specific failed job
await client.retryDlq('emails', 123);

// Retry ALL failed jobs in queue
await client.retryDlq('emails');

// Discard a job directly to DLQ
await client.discard(456);</code></pre>
        </div>

        <h3>DLQ Best Practices</h3>
        <div class="card-grid">
          <div class="card">
            <h4>Monitor Regularly</h4>
            <p>Set up alerts for DLQ growth. A growing DLQ indicates systemic issues.</p>
          </div>
          <div class="card">
            <h4>Log Failures</h4>
            <p>Include detailed error messages in job failures for easier debugging.</p>
          </div>
          <div class="card">
            <h4>Automate Retries</h4>
            <p>For transient errors, set up automatic retry schedules during off-peak hours.</p>
          </div>
          <div class="card">
            <h4>Clean Periodically</h4>
            <p>Use <code>clean()</code> to remove old DLQ entries after investigation.</p>
          </div>
        </div>
      </section>

      <!-- Progress Tracking -->
      <section id="progress">
        <h2>Progress Tracking</h2>
        <p>Track job progress in real-time for long-running tasks like file processing or AI inference.</p>

        <div class="code-block">
          <div class="code-block-header">
            <span>progress-tracking.ts</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-typescript">import { Queue, Worker, FlashQ } from 'flashq';

const queue = new Queue('processing');
const client = new FlashQ();

// Worker that reports progress
new Worker('processing', async (job) => {
  const items = job.data.items;
  const results = [];

  for (let i = 0; i < items.length; i++) {
    // Process item
    const result = await processItem(items[i]);
    results.push(result);

    // Update progress (0-100)
    const progress = Math.round(((i + 1) / items.length) * 100);
    await job.updateProgress(progress, `Processed ${i + 1}/${items.length}`);
  }

  return results;
});

// Monitor progress from producer
const job = await queue.add('batch', { items: largeArray });

// Poll progress
const interval = setInterval(async () => {
  const { progress, message } = await client.getProgress(job.id);
  console.log(`Progress: ${progress}% - ${message}`);

  if (progress === 100) {
    clearInterval(interval);
  }
}, 1000);

// Or listen to progress events
worker.on('progress', (job, progress) => {
  console.log(`Job ${job.id}: ${progress}%`);
});</code></pre>
        </div>

        <div class="callout callout-info">
          <div class="callout-title">üí° Heartbeat for Long Jobs</div>
          <p>For jobs running longer than the timeout, use <code>job.heartbeat()</code> to prevent stall detection from failing the job.</p>
        </div>
      </section>

      <!-- Self-Hosting -->
      <section id="self-hosting">
        <h2>Self-Hosting</h2>
        <p>flashQ is designed for easy self-hosting. Run it on any Linux, macOS, or container environment.</p>

        <h3>System Requirements</h3>
        <table>
          <thead>
            <tr>
              <th>Component</th>
              <th>Minimum</th>
              <th>Recommended</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>CPU</td><td>1 core</td><td>2+ cores</td></tr>
            <tr><td>Memory</td><td>512 MB</td><td>1-2 GB</td></tr>
            <tr><td>Disk</td><td>100 MB</td><td>1 GB (for persistence)</td></tr>
            <tr><td>OS</td><td colspan="2">Linux (x86_64, arm64), macOS</td></tr>
          </tbody>
        </table>

        <h3>Binary Installation</h3>
        <div class="code-block">
          <pre><code class="language-bash"># Linux x86_64
curl -L https://github.com/egeominotti/flashq/releases/latest/download/flashq-linux-x86_64.tar.gz | tar xz
sudo mv flashq-server /usr/local/bin/

# Linux ARM64 (Raspberry Pi, AWS Graviton)
curl -L https://github.com/egeominotti/flashq/releases/latest/download/flashq-linux-arm64.tar.gz | tar xz
sudo mv flashq-server /usr/local/bin/

# macOS Apple Silicon
curl -L https://github.com/egeominotti/flashq/releases/latest/download/flashq-macos-arm64.tar.gz | tar xz
sudo mv flashq-server /usr/local/bin/</code></pre>
        </div>

        <h3>Systemd Service</h3>
        <div class="code-block">
          <div class="code-block-header">
            <span>/etc/systemd/system/flashq.service</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-ini">[Unit]
Description=flashQ Job Queue Server
After=network.target postgresql.service

[Service]
Type=simple
User=flashq
Environment=HTTP=1
Environment=DATABASE_URL=postgres://flashq:password@localhost/flashq
ExecStart=/usr/local/bin/flashq-server
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target</code></pre>
        </div>

        <div class="code-block">
          <pre><code class="language-bash"># Enable and start
sudo systemctl enable flashq
sudo systemctl start flashq

# Check status
sudo systemctl status flashq

# View logs
sudo journalctl -u flashq -f</code></pre>
        </div>
      </section>

      <!-- Docker -->
      <section id="docker">
        <h2>Docker</h2>
        <p>The recommended way to run flashQ in production.</p>

        <h3>Quick Start</h3>
        <div class="code-block">
          <pre><code class="language-bash"># Run with dashboard enabled
docker run -d --name flashq \
  -p 6789:6789 \
  -p 6790:6790 \
  -e HTTP=1 \
  ghcr.io/egeominotti/flashq:latest</code></pre>
        </div>

        <h3>Docker Compose (Production)</h3>
        <div class="code-block">
          <div class="code-block-header">
            <span>docker-compose.yml</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-yaml">version: '3.8'

services:
  flashq:
    image: ghcr.io/egeominotti/flashq:latest
    ports:
      - "6789:6789"   # TCP
      - "6790:6790"   # HTTP/Dashboard
    environment:
      - HTTP=1
      - DATABASE_URL=postgres://flashq:secret@postgres:5432/flashq
      - AUTH_TOKENS=your-secret-token
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: flashq
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: flashq
    volumes:
      - flashq_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U flashq"]
      interval: 5s
      timeout: 5s
      retries: 5

volumes:
  flashq_data:</code></pre>
        </div>

        <h3>Environment Variables</h3>
        <table>
          <thead>
            <tr>
              <th>Variable</th>
              <th>Default</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><code>PORT</code></td><td>6789</td><td>TCP port for client connections</td></tr>
            <tr><td><code>HTTP</code></td><td>0</td><td>Enable HTTP API (1 = enabled)</td></tr>
            <tr><td><code>HTTP_PORT</code></td><td>6790</td><td>HTTP API and dashboard port</td></tr>
            <tr><td><code>GRPC</code></td><td>0</td><td>Enable gRPC API (1 = enabled)</td></tr>
            <tr><td><code>GRPC_PORT</code></td><td>6791</td><td>gRPC API port</td></tr>
            <tr><td><code>DATABASE_URL</code></td><td>-</td><td>PostgreSQL connection string</td></tr>
            <tr><td><code>AUTH_TOKENS</code></td><td>-</td><td>Comma-separated auth tokens</td></tr>
            <tr><td><code>CLUSTER_MODE</code></td><td>0</td><td>Enable clustering (1 = enabled)</td></tr>
            <tr><td><code>NODE_ID</code></td><td>auto</td><td>Unique node ID for clustering</td></tr>
          </tbody>
        </table>
      </section>

      <!-- Clustering -->
      <section id="clustering">
        <h2>Clustering (High Availability)</h2>
        <p>Run multiple flashQ nodes for high availability. PostgreSQL is used for coordination and leader election.</p>

        <h3>Architecture</h3>
        <div class="code-block">
          <pre><code class="language-plaintext">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Node 1  ‚îÇ    ‚îÇ  Node 2  ‚îÇ    ‚îÇ  Node 3  ‚îÇ
‚îÇ (Leader) ‚îÇ    ‚îÇ(Follower)‚îÇ    ‚îÇ(Follower)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ               ‚îÇ               ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  PostgreSQL ‚îÇ
              ‚îÇ  (Shared)   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
        </div>

        <h3>How It Works</h3>
        <ul>
          <li><strong>Leader election</strong>: Uses PostgreSQL advisory locks (<code>pg_try_advisory_lock</code>)</li>
          <li><strong>Leader responsibilities</strong>: Runs background tasks (cron, cleanup, timeouts)</li>
          <li><strong>All nodes</strong>: Handle client requests (push/pull/ack)</li>
          <li><strong>Automatic failover</strong>: Within 5 seconds when leader crashes</li>
          <li><strong>Health checks</strong>: Stale nodes cleaned after 30s of no heartbeat</li>
        </ul>

        <h3>Multi-Node Setup</h3>
        <div class="code-block">
          <div class="code-block-header">
            <span>docker-compose.ha.yml</span>
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          </div>
          <pre><code class="language-yaml">version: '3.8'

services:
  flashq-node1:
    image: ghcr.io/egeominotti/flashq:latest
    ports:
      - "6789:6789"
      - "6790:6790"
    environment:
      - CLUSTER_MODE=1
      - NODE_ID=node-1
      - HTTP=1
      - DATABASE_URL=postgres://flashq:secret@postgres:5432/flashq
    depends_on:
      - postgres

  flashq-node2:
    image: ghcr.io/egeominotti/flashq:latest
    ports:
      - "6793:6789"
      - "6794:6790"
    environment:
      - CLUSTER_MODE=1
      - NODE_ID=node-2
      - HTTP=1
      - DATABASE_URL=postgres://flashq:secret@postgres:5432/flashq
    depends_on:
      - postgres

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: flashq
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: flashq
    volumes:
      - ha_data:/var/lib/postgresql/data

volumes:
  ha_data:</code></pre>
        </div>

        <h3>Cluster Endpoints</h3>
        <table>
          <thead>
            <tr>
              <th>Endpoint</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><code>GET /health</code></td><td>Node health with leader/follower status</td></tr>
            <tr><td><code>GET /cluster/nodes</code></td><td>List all nodes in cluster</td></tr>
          </tbody>
        </table>

        <div class="code-block">
          <pre><code class="language-bash"># Check cluster status
curl http://localhost:6790/cluster/nodes

# Response
{
  "nodes": [
    { "id": "node-1", "host": "flashq-node1", "is_leader": true },
    { "id": "node-2", "host": "flashq-node2", "is_leader": false }
  ]
}</code></pre>
        </div>
      </section>

      <!-- Configuration -->
      <section id="configuration">
        <h2>Configuration</h2>
        <p>Configure the flashQ server with environment variables.</p>

        <table>
          <thead>
            <tr>
              <th>Variable</th>
              <th>Default</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>PORT</code></td>
              <td><code>6789</code></td>
              <td>TCP port for client connections</td>
            </tr>
            <tr>
              <td><code>HTTP</code></td>
              <td><code>0</code></td>
              <td>Enable HTTP API and dashboard (set to <code>1</code>)</td>
            </tr>
            <tr>
              <td><code>HTTP_PORT</code></td>
              <td><code>6790</code></td>
              <td>HTTP API port</td>
            </tr>
            <tr>
              <td><code>DATABASE_URL</code></td>
              <td>-</td>
              <td>PostgreSQL connection URL for persistence</td>
            </tr>
            <tr>
              <td><code>AUTH_TOKENS</code></td>
              <td>-</td>
              <td>Comma-separated list of valid auth tokens</td>
            </tr>
            <tr>
              <td><code>CLUSTER_MODE</code></td>
              <td><code>0</code></td>
              <td>Enable clustering (set to <code>1</code>)</td>
            </tr>
          </tbody>
        </table>

        <h3>Example: Production Docker</h3>
        <div class="code-block">
          <pre><code class="language-bash">docker run -d --name flashq \
  -p 6789:6789 \
  -p 6790:6790 \
  -e HTTP=1 \
  -e DATABASE_URL=postgres://user:pass@db:5432/flashq \
  -e AUTH_TOKENS=secret1,secret2 \
  ghcr.io/egeominotti/flashq:latest</code></pre>
        </div>
      </section>

      <!-- Migration from BullMQ -->
      <section id="from-bullmq">
        <h2>Migration from BullMQ</h2>
        <p>flashQ uses a BullMQ-compatible API, making migration straightforward.</p>

        <div class="steps">
          <div class="step">
            <h4>Install flashQ SDK</h4>
            <div class="code-block">
              <pre><code class="language-bash">bun add flashq</code></pre>
            </div>
          </div>

          <div class="step">
            <h4>Start the flashQ server</h4>
            <div class="code-block">
              <pre><code class="language-bash">docker run -d -p 6789:6789 ghcr.io/egeominotti/flashq:latest</code></pre>
            </div>
          </div>

          <div class="step">
            <h4>Update your imports</h4>
            <div class="code-block">
              <pre><code class="language-typescript">// Before (BullMQ)
import { Queue, Worker } from 'bullmq';

// After (flashQ)
import { Queue, Worker } from 'flashq';</code></pre>
            </div>
          </div>

          <div class="step">
            <h4>Remove Redis configuration</h4>
            <div class="code-block">
              <pre><code class="language-typescript">// Before (BullMQ)
const queue = new Queue('emails', {
  connection: { host: 'localhost', port: 6379 }
});

// After (flashQ) - no Redis needed!
const queue = new Queue('emails');</code></pre>
            </div>
          </div>
        </div>

        <div class="callout callout-success">
          <div class="callout-title">‚úÖ That's it!</div>
          <p>Your code should work without any other changes. The Queue and Worker APIs are compatible.</p>
        </div>
      </section>

      <!-- API Reference -->
      <section id="api-reference">
        <h2>API Reference</h2>
        <p>Complete reference for all SDK methods and server commands.</p>

        <h3>Queue Class</h3>
        <table>
          <thead>
            <tr>
              <th>Method</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><code>add(name, data, opts?)</code></td><td>Add a single job to the queue</td></tr>
            <tr><td><code>addBulk(jobs)</code></td><td>Add multiple jobs in batch</td></tr>
            <tr><td><code>getJob(jobId)</code></td><td>Get job by ID with current state</td></tr>
            <tr><td><code>getJobs(state?, limit?, offset?)</code></td><td>List jobs with filtering and pagination</td></tr>
            <tr><td><code>getJobCounts()</code></td><td>Get counts by state</td></tr>
            <tr><td><code>count()</code></td><td>Count waiting + delayed jobs</td></tr>
            <tr><td><code>finished(jobId, timeout?)</code></td><td>Wait for job completion</td></tr>
            <tr><td><code>pause()</code></td><td>Pause the queue</td></tr>
            <tr><td><code>resume()</code></td><td>Resume the queue</td></tr>
            <tr><td><code>isPaused()</code></td><td>Check if queue is paused</td></tr>
            <tr><td><code>drain()</code></td><td>Remove all waiting jobs</td></tr>
            <tr><td><code>obliterate()</code></td><td>Remove ALL queue data</td></tr>
            <tr><td><code>clean(grace, state, limit?)</code></td><td>Cleanup by age and state</td></tr>
            <tr><td><code>close()</code></td><td>Close connection</td></tr>
          </tbody>
        </table>

        <h3>Worker Class</h3>
        <table>
          <thead>
            <tr>
              <th>Method / Event</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><code>run()</code></td><td>Start processing (if autorun=false)</td></tr>
            <tr><td><code>pause()</code></td><td>Pause the worker</td></tr>
            <tr><td><code>resume()</code></td><td>Resume the worker</td></tr>
            <tr><td><code>close()</code></td><td>Stop and close connections</td></tr>
            <tr><td><code>on('completed')</code></td><td>Job completed event</td></tr>
            <tr><td><code>on('failed')</code></td><td>Job failed event</td></tr>
            <tr><td><code>on('active')</code></td><td>Job started event</td></tr>
            <tr><td><code>on('progress')</code></td><td>Progress update event</td></tr>
            <tr><td><code>on('error')</code></td><td>Worker error event</td></tr>
          </tbody>
        </table>

        <h3>FlashQ Client (Low-Level)</h3>
        <table>
          <thead>
            <tr>
              <th>Method</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><code>connect()</code></td><td>Connect to server</td></tr>
            <tr><td><code>close()</code></td><td>Close connection</td></tr>
            <tr><td><code>auth(token)</code></td><td>Authenticate with token</td></tr>
            <tr><td><code>push(queue, data, opts?)</code></td><td>Push a job</td></tr>
            <tr><td><code>pushBatch(queue, jobs)</code></td><td>Push multiple jobs</td></tr>
            <tr><td><code>pull(queue)</code></td><td>Pull a job (blocking)</td></tr>
            <tr><td><code>pullBatch(queue, count)</code></td><td>Pull multiple jobs</td></tr>
            <tr><td><code>ack(jobId, result?)</code></td><td>Acknowledge completion</td></tr>
            <tr><td><code>ackBatch(jobIds)</code></td><td>Batch acknowledge</td></tr>
            <tr><td><code>fail(jobId, error?)</code></td><td>Fail a job</td></tr>
            <tr><td><code>cancel(jobId)</code></td><td>Cancel pending job</td></tr>
            <tr><td><code>getJob(jobId)</code></td><td>Get job details</td></tr>
            <tr><td><code>getState(jobId)</code></td><td>Get job state only</td></tr>
            <tr><td><code>getResult(jobId)</code></td><td>Get job result</td></tr>
            <tr><td><code>getJobByCustomId(customId)</code></td><td>Lookup by custom ID</td></tr>
            <tr><td><code>progress(jobId, pct, msg?)</code></td><td>Update progress</td></tr>
            <tr><td><code>getProgress(jobId)</code></td><td>Get job progress</td></tr>
            <tr><td><code>update(jobId, data)</code></td><td>Update job data</td></tr>
            <tr><td><code>changePriority(jobId, pri)</code></td><td>Change priority</td></tr>
            <tr><td><code>moveToDelayed(jobId, delay)</code></td><td>Move to delayed</td></tr>
            <tr><td><code>promote(jobId)</code></td><td>Move delayed to waiting</td></tr>
            <tr><td><code>discard(jobId)</code></td><td>Move to DLQ</td></tr>
            <tr><td><code>heartbeat(jobId)</code></td><td>Send heartbeat</td></tr>
            <tr><td><code>log(jobId, msg, level?)</code></td><td>Add log entry</td></tr>
            <tr><td><code>getLogs(jobId)</code></td><td>Get job logs</td></tr>
            <tr><td><code>getDlq(queue, count?)</code></td><td>Get DLQ jobs</td></tr>
            <tr><td><code>retryDlq(queue, jobId?)</code></td><td>Retry DLQ jobs</td></tr>
            <tr><td><code>setRateLimit(queue, limit)</code></td><td>Set rate limit</td></tr>
            <tr><td><code>clearRateLimit(queue)</code></td><td>Clear rate limit</td></tr>
            <tr><td><code>setConcurrency(queue, limit)</code></td><td>Set concurrency</td></tr>
            <tr><td><code>clearConcurrency(queue)</code></td><td>Clear concurrency</td></tr>
            <tr><td><code>addCron(name, options)</code></td><td>Add cron job</td></tr>
            <tr><td><code>deleteCron(name)</code></td><td>Delete cron job</td></tr>
            <tr><td><code>listCrons()</code></td><td>List cron jobs</td></tr>
            <tr><td><code>stats()</code></td><td>Get queue statistics</td></tr>
            <tr><td><code>metrics()</code></td><td>Get detailed metrics</td></tr>
            <tr><td><code>listQueues()</code></td><td>List all queues</td></tr>
          </tbody>
        </table>

        <h3>Job Options (Complete)</h3>
        <table>
          <thead>
            <tr>
              <th>Option</th>
              <th>Type</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><code>priority</code></td><td>number</td><td>Higher = processed first</td></tr>
            <tr><td><code>delay</code></td><td>number</td><td>Delay in milliseconds</td></tr>
            <tr><td><code>attempts</code></td><td>number</td><td>Max retry attempts</td></tr>
            <tr><td><code>backoff</code></td><td>number | object</td><td>Retry backoff strategy</td></tr>
            <tr><td><code>timeout</code></td><td>number</td><td>Processing timeout (ms)</td></tr>
            <tr><td><code>ttl</code></td><td>number</td><td>Time-to-live (ms)</td></tr>
            <tr><td><code>jobId</code></td><td>string</td><td>Custom ID for idempotency</td></tr>
            <tr><td><code>depends_on</code></td><td>number[]</td><td>Job dependencies</td></tr>
            <tr><td><code>unique_key</code></td><td>string</td><td>Deduplication key</td></tr>
            <tr><td><code>tags</code></td><td>string[]</td><td>Job tags for filtering</td></tr>
            <tr><td><code>lifo</code></td><td>boolean</td><td>Last-in-first-out mode</td></tr>
            <tr><td><code>stall_timeout</code></td><td>number</td><td>Stall detection (ms)</td></tr>
            <tr><td><code>debounce_id</code></td><td>string</td><td>Debounce identifier</td></tr>
            <tr><td><code>debounce_ttl</code></td><td>number</td><td>Debounce window (ms)</td></tr>
            <tr><td><code>keepCompletedAge</code></td><td>number</td><td>Keep result for duration (ms)</td></tr>
            <tr><td><code>keepCompletedCount</code></td><td>number</td><td>Keep in last N completed</td></tr>
          </tbody>
        </table>

        <h3>HTTP API Endpoints</h3>
        <table>
          <thead>
            <tr>
              <th>Method</th>
              <th>Endpoint</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><span class="api-method api-method-get">GET</td><td><code>/health</code></td><td>Health check</td></tr>
            <tr><td><span class="api-method api-method-get">GET</td><td><code>/metrics/prometheus</code></td><td>Prometheus metrics</td></tr>
            <tr><td><span class="api-method api-method-get">GET</td><td><code>/cluster/nodes</code></td><td>List cluster nodes</td></tr>
            <tr><td><span class="api-method api-method-post">POST</td><td><code>/api/push</code></td><td>Push job via HTTP</td></tr>
            <tr><td><span class="api-method api-method-post">POST</td><td><code>/api/pull</code></td><td>Pull job via HTTP</td></tr>
            <tr><td><span class="api-method api-method-post">POST</td><td><code>/api/ack</code></td><td>Acknowledge job</td></tr>
            <tr><td><span class="api-method api-method-get">GET</td><td><code>/api/job/:id</code></td><td>Get job details</td></tr>
            <tr><td><span class="api-method api-method-get">GET</td><td><code>/api/stats</code></td><td>Queue statistics</td></tr>
          </tbody>
        </table>
      </section>

      <!-- Troubleshooting -->
      <section id="troubleshooting">
        <h2>Troubleshooting</h2>

        <h3>Connection refused</h3>
        <p><strong>Error:</strong> <code>ECONNREFUSED 127.0.0.1:6789</code></p>
        <p><strong>Solution:</strong> Make sure the flashQ server is running:</p>
        <div class="code-block">
          <pre><code class="language-bash">docker ps | grep flashq</code></pre>
        </div>

        <h3>Job timeout</h3>
        <p><strong>Error:</strong> Job exceeds processing timeout</p>
        <p><strong>Solution:</strong> Increase the timeout in job options:</p>
        <div class="code-block">
          <pre><code class="language-typescript">await queue.add('long-job', data, {
  timeout: 300000 // 5 minutes
});</code></pre>
        </div>

        <h3>Authentication failed</h3>
        <p><strong>Error:</strong> <code>AUTH_FAILED</code></p>
        <p><strong>Solution:</strong> Set the token in your client configuration:</p>
        <div class="code-block">
          <pre><code class="language-typescript">const queue = new Queue('emails', {
  token: 'your-auth-token'
});</code></pre>
        </div>

        <h3>Job stuck in active state</h3>
        <p><strong>Error:</strong> Job remains active after worker crash</p>
        <p><strong>Solution:</strong> Jobs are automatically recovered after the stall timeout. For long jobs, use heartbeat:</p>
        <div class="code-block">
          <pre><code class="language-typescript">new Worker('queue', async (job) => {
  for (const item of items) {
    await processItem(item);
    await job.heartbeat();  // Prevent stall detection
  }
});</code></pre>
        </div>

        <h3>Memory usage growing</h3>
        <p><strong>Cause:</strong> Completed jobs and results accumulating</p>
        <p><strong>Solution:</strong> Configure retention or use clean():</p>
        <div class="code-block">
          <pre><code class="language-typescript">// During job creation
await queue.add('job', data, {
  keepCompletedAge: 3600000,  // Keep for 1 hour
  keepCompletedCount: 1000   // Keep last 1000
});

// Manual cleanup
await queue.clean(3600000, 'completed');</code></pre>
        </div>
      </section>

    </main>
  </div>

  <!-- Mobile menu toggle -->
  <button class="mobile-menu-toggle" onclick="toggleSidebar()">‚ò∞</button>

  <!-- Scripts -->
  <script src="script.js"></script>
  <script>
    // Initialize Lucide icons
    lucide.createIcons();
    // Initialize Highlight.js
    hljs.highlightAll();
  </script>
</body>
</html>
